{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2834, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>excerpt</th>\n",
       "      <th>target</th>\n",
       "      <th>standard_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c12129c31</td>\n",
       "      <td>When the young people returned to the ballroom...</td>\n",
       "      <td>-0.340259</td>\n",
       "      <td>0.464009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>85aa80a4c</td>\n",
       "      <td>All through dinner time, Mrs. Fayre was somewh...</td>\n",
       "      <td>-0.315372</td>\n",
       "      <td>0.480805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b69ac6792</td>\n",
       "      <td>As Roger had predicted, the snow departed as q...</td>\n",
       "      <td>-0.580118</td>\n",
       "      <td>0.476676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dd1000b26</td>\n",
       "      <td>And outside before the palace a great garden w...</td>\n",
       "      <td>-1.054013</td>\n",
       "      <td>0.450007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37c1b32fb</td>\n",
       "      <td>Once upon a time there were Three Bears who li...</td>\n",
       "      <td>0.247197</td>\n",
       "      <td>0.510845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>f9bf357fe</td>\n",
       "      <td>Hal and Chester found ample time to take an in...</td>\n",
       "      <td>-0.861809</td>\n",
       "      <td>0.480936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>eaf8e7355</td>\n",
       "      <td>Hal Paine and Chester Crawford were typical Am...</td>\n",
       "      <td>-1.759061</td>\n",
       "      <td>0.476507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0a43a07f1</td>\n",
       "      <td>On the twenty-second of February, 1916, an aut...</td>\n",
       "      <td>-0.952325</td>\n",
       "      <td>0.498116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>f7eff7419</td>\n",
       "      <td>The boys left the capitol and made their way d...</td>\n",
       "      <td>-0.371641</td>\n",
       "      <td>0.463710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>d96e6dbcd</td>\n",
       "      <td>One day he had gone beyond any point which he ...</td>\n",
       "      <td>-1.238432</td>\n",
       "      <td>0.465900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                            excerpt    target  \\\n",
       "0  c12129c31  When the young people returned to the ballroom... -0.340259   \n",
       "1  85aa80a4c  All through dinner time, Mrs. Fayre was somewh... -0.315372   \n",
       "2  b69ac6792  As Roger had predicted, the snow departed as q... -0.580118   \n",
       "3  dd1000b26  And outside before the palace a great garden w... -1.054013   \n",
       "4  37c1b32fb  Once upon a time there were Three Bears who li...  0.247197   \n",
       "5  f9bf357fe  Hal and Chester found ample time to take an in... -0.861809   \n",
       "6  eaf8e7355  Hal Paine and Chester Crawford were typical Am... -1.759061   \n",
       "7  0a43a07f1  On the twenty-second of February, 1916, an aut... -0.952325   \n",
       "8  f7eff7419  The boys left the capitol and made their way d... -0.371641   \n",
       "9  d96e6dbcd  One day he had gone beyond any point which he ... -1.238432   \n",
       "\n",
       "   standard_error  \n",
       "0        0.464009  \n",
       "1        0.480805  \n",
       "2        0.476676  \n",
       "3        0.450007  \n",
       "4        0.510845  \n",
       "5        0.480936  \n",
       "6        0.476507  \n",
       "7        0.498116  \n",
       "8        0.463710  \n",
       "9        0.465900  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"commonlitreadabilityprize/train.csv\")\n",
    "df = df.drop(columns=[\"url_legal\", \"license\"])\n",
    "print(df.shape)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-3.676267773 1.711389827\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df[\"target\"].hist(bins=20)\n",
    "print(df[\"target\"].min(), df[\"target\"].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# added grade column based on excerpt\n",
    "# use standard error to adjust scores with the confidence level\n",
    "\n",
    "df['grade'] = pd.cut(df['target'], bins=[-2.35, -1.875, -1.53, -1.199, -1.192, -0.643, -0.466, -.136, .47 , .81, 1.71], labels=range(12, 2, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Layer\n",
    "\n",
    "@tf.keras.utils.register_keras_serializable()\n",
    "class ReadabilityScoreLayer(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(ReadabilityScoreLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Split text by spaces to estimate word count\n",
    "        words = tf.strings.split(inputs)\n",
    "        word_count = tf.map_fn(lambda x: tf.size(x), words, fn_output_signature=tf.int32)\n",
    "        word_count = tf.cast(word_count, tf.float32)\n",
    "        \n",
    "        # Estimate sentence count by counting periods ('.')\n",
    "        sentence_count = tf.strings.regex_replace(inputs, r\"[^\\.]\", \"\")\n",
    "        sentence_count = tf.strings.length(sentence_count)\n",
    "        sentence_count = tf.cast(sentence_count, tf.float32)\n",
    "        sentence_count = tf.maximum(sentence_count, 1.0)  # Avoid division by zero\n",
    "\n",
    "        # Simplified readability score calculation\n",
    "        readability_score = (0.39 * (word_count / sentence_count)) + (11.8 * (word_count / word_count)) - 15.59\n",
    "        \n",
    "        # Expand dimensions to match (batch_size, 1)\n",
    "        return tf.expand_dims(readability_score, axis=-1)\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        # Define the output shape (batch_size, 1)\n",
    "        return (input_shape[0], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and validation sets\n",
    "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import TextVectorization, Embedding, GlobalAveragePooling1D, Dense, Dropout, Input, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Define the inputs\n",
    "text_input = Input(shape=(), dtype=tf.string, name=\"text_input\")\n",
    "\n",
    "# Text Vectorization and Embedding\n",
    "vectorizer = TextVectorization(max_tokens=10000, output_sequence_length=200)\n",
    "vectorizer.adapt(df['excerpt'])  # Fit vectorizer on the text data\n",
    "text_vectorized = vectorizer(text_input)\n",
    "embedding = Embedding(input_dim=10000, output_dim=128)(text_vectorized)\n",
    "pooled_text = GlobalAveragePooling1D()(embedding)\n",
    "\n",
    "# Readability Score Calculation\n",
    "readability_score = ReadabilityScoreLayer()(text_input)  # Calculates readability score internally\n",
    "\n",
    "# Concatenate text features and readability score\n",
    "concatenated = Concatenate()([pooled_text, readability_score])\n",
    "\n",
    "# Define the dense layers for regression\n",
    "dense1 = Dense(128, activation=\"relu\")(concatenated)\n",
    "dropout1 = Dropout(0.5)(dense1)\n",
    "dense2 = Dense(64, activation=\"relu\")(dropout1)\n",
    "dropout2 = Dropout(0.5)(dense2)\n",
    "\n",
    "# Output layer\n",
    "output = Dense(1, name=\"target_output\")(dropout2)\n",
    "\n",
    "# Define the model\n",
    "model = Model(inputs=text_input, outputs=output)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 2.2490 - mae: 1.1066 - val_loss: 1.0534 - val_mae: 0.8222\n",
      "Epoch 2/10\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.1556 - mae: 0.8436 - val_loss: 0.8581 - val_mae: 0.7491\n",
      "Epoch 3/10\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.9838 - mae: 0.7822 - val_loss: 0.6882 - val_mae: 0.6812\n",
      "Epoch 4/10\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.6906 - mae: 0.6471 - val_loss: 0.5644 - val_mae: 0.6079\n",
      "Epoch 5/10\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5733 - mae: 0.5974 - val_loss: 0.5640 - val_mae: 0.6065\n",
      "Epoch 6/10\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4975 - mae: 0.5539 - val_loss: 0.4912 - val_mae: 0.5582\n",
      "Epoch 7/10\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4385 - mae: 0.5196 - val_loss: 0.5023 - val_mae: 0.5652\n",
      "Epoch 8/10\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4020 - mae: 0.4833 - val_loss: 0.4840 - val_mae: 0.5526\n",
      "Epoch 9/10\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3505 - mae: 0.4476 - val_loss: 0.4738 - val_mae: 0.5453\n",
      "Epoch 10/10\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.2733 - mae: 0.3991 - val_loss: 0.4873 - val_mae: 0.5543\n"
     ]
    }
   ],
   "source": [
    "# Assuming train_df has 'excerpt' and 'target' columns\n",
    "train_texts = train_df['excerpt']\n",
    "train_targets = train_df['target']\n",
    "\n",
    "# Train the model using only the text input\n",
    "history = model.fit(\n",
    "    train_texts,\n",
    "    train_targets,\n",
    "    validation_split=0.2,\n",
    "    epochs=10,\n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 7 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001201526EAC0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 7 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001201526EAC0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step\n",
      "                                             excerpt  predictions grade\n",
      "0  Katie was six years old. She was part of a big...     0.783582     4\n",
      "1  Emma was very excited. Today was the champions...     0.350066     5\n",
      "2  Most babies’ first words are something like “D...    -0.305825     6\n",
      "3  Juneteenth, celebrated on June 19th, is a sign...    -0.661693     8\n",
      "4  Mary Boykin Miller Chesnut (1823-1886) was a p...     0.277720     5\n",
      "5  He told me what had happened to him and his co...     0.254660     5\n",
      "6  Mine eye and heart are at a mortal war,\\nHow t...    -1.444685    10\n"
     ]
    }
   ],
   "source": [
    "import textstat\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow as tf\n",
    "\n",
    "# Load the test data\n",
    "test_df = pd.read_csv(\"commonlitreadabilityprize/test copy.csv\")\n",
    "test_texts = test_df['excerpt']\n",
    "\n",
    "# Predict without needing to compute readability scores manually\n",
    "predictions = model.predict(test_texts)\n",
    "test_df['predictions'] = predictions\n",
    "test_df['grade'] = pd.cut(test_df['predictions'], bins=[-2.35, -1.875, -1.53, -1.199, -1.192, -0.643, -0.466, -.136, .47 , .81, 1.71], labels=range(12, 2, -1))\n",
    "\n",
    "# Display predictions\n",
    "print(test_df[['excerpt', 'predictions', 'grade']])\n",
    "\n",
    "model.save(\"model.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Functional' object has no attribute '_get_save_spec'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[104], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m converter \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mlite\u001b[38;5;241m.\u001b[39mTFLiteConverter\u001b[38;5;241m.\u001b[39mfrom_keras_model(model)\n\u001b[0;32m      6\u001b[0m converter\u001b[38;5;241m.\u001b[39moptimizations \u001b[38;5;241m=\u001b[39m [tf\u001b[38;5;241m.\u001b[39mlite\u001b[38;5;241m.\u001b[39mOptimize\u001b[38;5;241m.\u001b[39mDEFAULT]  \u001b[38;5;66;03m# Optional: Apply optimizations to reduce size\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m tflite_model \u001b[38;5;241m=\u001b[39m \u001b[43mconverter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Save the TFLite model to a file\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel.tflite\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "File \u001b[1;32mc:\\Users\\yxl21\\Documents\\School\\hacktx2024\\.venv\\Lib\\site-packages\\tensorflow\\lite\\python\\lite.py:1238\u001b[0m, in \u001b[0;36m_export_metrics.<locals>.wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1235\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(convert_func)\n\u001b[0;32m   1236\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m   1237\u001b[0m   \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m-> 1238\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_and_export_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\yxl21\\Documents\\School\\hacktx2024\\.venv\\Lib\\site-packages\\tensorflow\\lite\\python\\lite.py:1190\u001b[0m, in \u001b[0;36mTFLiteConverterBase._convert_and_export_metrics\u001b[1;34m(self, convert_func, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1188\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save_conversion_params_metric()\n\u001b[0;32m   1189\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mprocess_time()\n\u001b[1;32m-> 1190\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1191\u001b[0m elapsed_time_ms \u001b[38;5;241m=\u001b[39m (time\u001b[38;5;241m.\u001b[39mprocess_time() \u001b[38;5;241m-\u001b[39m start_time) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1000\u001b[39m\n\u001b[0;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result:\n",
      "File \u001b[1;32mc:\\Users\\yxl21\\Documents\\School\\hacktx2024\\.venv\\Lib\\site-packages\\tensorflow\\lite\\python\\lite.py:1759\u001b[0m, in \u001b[0;36mTFLiteKerasModelConverterV2.convert\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1755\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m saved_model_convert_result:\n\u001b[0;32m   1756\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m saved_model_convert_result\n\u001b[0;32m   1758\u001b[0m graph_def, input_tensors, output_tensors, frozen_func \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m-> 1759\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_freeze_keras_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1760\u001b[0m )\n\u001b[0;32m   1762\u001b[0m graph_def \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimize_tf_model(\n\u001b[0;32m   1763\u001b[0m     graph_def, input_tensors, output_tensors, frozen_func\n\u001b[0;32m   1764\u001b[0m )\n\u001b[0;32m   1766\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m(TFLiteKerasModelConverterV2, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mconvert(\n\u001b[0;32m   1767\u001b[0m     graph_def, input_tensors, output_tensors\n\u001b[0;32m   1768\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\yxl21\\Documents\\School\\hacktx2024\\.venv\\Lib\\site-packages\\tensorflow\\lite\\python\\convert_phase.py:215\u001b[0m, in \u001b[0;36mconvert_phase.<locals>.actual_decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m error:\n\u001b[0;32m    214\u001b[0m   report_error_message(\u001b[38;5;28mstr\u001b[39m(error))\n\u001b[1;32m--> 215\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m error \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\yxl21\\Documents\\School\\hacktx2024\\.venv\\Lib\\site-packages\\tensorflow\\lite\\python\\convert_phase.py:205\u001b[0m, in \u001b[0;36mconvert_phase.<locals>.actual_decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    202\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    203\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    204\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 205\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    206\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m ConverterError \u001b[38;5;28;01mas\u001b[39;00m converter_error:\n\u001b[0;32m    207\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m converter_error\u001b[38;5;241m.\u001b[39merrors:\n",
      "File \u001b[1;32mc:\\Users\\yxl21\\Documents\\School\\hacktx2024\\.venv\\Lib\\site-packages\\tensorflow\\lite\\python\\lite.py:1700\u001b[0m, in \u001b[0;36mTFLiteKerasModelConverterV2._freeze_keras_model\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1691\u001b[0m \u001b[38;5;66;03m# If the model's call is not a `tf.function`, then we need to first get its\u001b[39;00m\n\u001b[0;32m   1692\u001b[0m \u001b[38;5;66;03m# input signature from `model_input_signature` method. We can't directly\u001b[39;00m\n\u001b[0;32m   1693\u001b[0m \u001b[38;5;66;03m# call `trace_model_call` because otherwise the batch dimension is set\u001b[39;00m\n\u001b[0;32m   1694\u001b[0m \u001b[38;5;66;03m# to None.\u001b[39;00m\n\u001b[0;32m   1695\u001b[0m \u001b[38;5;66;03m# Once we have better support for dynamic shapes, we can remove this.\u001b[39;00m\n\u001b[0;32m   1696\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_keras_model\u001b[38;5;241m.\u001b[39mcall, _def_function\u001b[38;5;241m.\u001b[39mFunction):\n\u001b[0;32m   1697\u001b[0m   \u001b[38;5;66;03m# Pass `keep_original_batch_size=True` will ensure that we get an input\u001b[39;00m\n\u001b[0;32m   1698\u001b[0m   \u001b[38;5;66;03m# signature including the batch dimension specified by the user.\u001b[39;00m\n\u001b[0;32m   1699\u001b[0m   \u001b[38;5;66;03m# TODO(b/169898786): Use the Keras public API when TFLite moves out of TF\u001b[39;00m\n\u001b[1;32m-> 1700\u001b[0m   input_signature \u001b[38;5;241m=\u001b[39m \u001b[43m_model_input_signature\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1701\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_keras_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeep_original_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[0;32m   1702\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1704\u001b[0m \u001b[38;5;66;03m# TODO(b/169898786): Use the Keras public API when TFLite moves out of TF\u001b[39;00m\n\u001b[0;32m   1705\u001b[0m func \u001b[38;5;241m=\u001b[39m _trace_model_call(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_keras_model, input_signature)\n",
      "File \u001b[1;32mc:\\Users\\yxl21\\Documents\\School\\hacktx2024\\.venv\\Lib\\site-packages\\tensorflow\\lite\\python\\tflite_keras_util.py:119\u001b[0m, in \u001b[0;36mmodel_input_signature\u001b[1;34m(model, keep_original_batch_size)\u001b[0m\n\u001b[0;32m    117\u001b[0m   input_specs \u001b[38;5;241m=\u001b[39m input_specs[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 119\u001b[0m   input_specs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_save_spec\u001b[49m(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    120\u001b[0m       dynamic_batch\u001b[38;5;241m=\u001b[39m\u001b[38;5;129;01mnot\u001b[39;00m keep_original_batch_size)\n\u001b[0;32m    121\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m input_specs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    122\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Functional' object has no attribute '_get_save_spec'"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model(\"model.keras\")  # Replace with your model's path\n",
    "\n",
    "\n",
    "# Convert the model to TensorFlow Lite format\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]  # Optional: Apply optimizations to reduce size\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the TFLite model to a file\n",
    "with open(\"model.tflite\", \"wb\") as f:\n",
    "    f.write(tflite_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
